{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1775a1a",
   "metadata": {},
   "source": [
    "# Applied Machine Learning Final Project\n",
    "\n",
    "**Student:** Jason Ballard\n",
    "\n",
    "**Course:** CSC 44670-80/81 – Applied Machine Learning\n",
    "\n",
    "**Date:** April 2025\n",
    "\n",
    "**Project:** Predicting Medical Charges Using Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159217e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0716d4a",
   "metadata": {},
   "source": [
    "## Project Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab166377",
   "metadata": {},
   "source": [
    "## Admin Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa020c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "\n",
    "import os\n",
    "\n",
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Scikit-learn: Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Scikit-learn: Models\n",
    "# from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "\n",
    "#  from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "\n",
    "# Scikit-learn: Preprocessing & Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Scikit-learn: Metrics\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error, \n",
    "    r2_score,\n",
    "   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder if it doesn't exist\n",
    "output_dir = \"plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Set up visual style\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a224a4",
   "metadata": {},
   "source": [
    "## Section 1. Import and Inspect the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f31e6",
   "metadata": {},
   "source": [
    "### 1.1 Load the dataset and display the first 10 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = \"data/insurance.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db25ba9",
   "metadata": {},
   "source": [
    "### 1.2 Check for missing values and display summary statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e39ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Display summary statistics\n",
    "summary_statistics = df.describe(include='all').transpose()\n",
    "\n",
    "missing_values, summary_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa5daef",
   "metadata": {},
   "source": [
    "#### Reflection 1:\n",
    "- _What do you notice about the dataset?_ \n",
    "The data set is clean with no missing values.  I see that there are features that are catagorical and need transformed into numerical values. \n",
    "\n",
    "- _Are there any data issues?_ \n",
    "I see that there are features that are catagorical and need transformed into numerical values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b30d2d",
   "metadata": {},
   "source": [
    "## Section 2. Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d66cfa",
   "metadata": {},
   "source": [
    "### 2.1 Explore data patterns and distributions\n",
    "- Create histograms, boxplots, and count plots for categorical variables (as applicable).\n",
    "- Identify patterns, outliers, and anomalies in feature distributions.\n",
    "- Check for class imbalance in the target variable (as applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6107c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for numerical features\n",
    "df.hist(bins=30, figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"histograms.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Boxplots to check for outliers\n",
    "plt.figure(figsize=(14, 6))\n",
    "for i, col in enumerate(['age', 'bmi', 'children', 'charges']):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"boxplots.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Count plots for categorical features\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i, col in enumerate(['sex', 'smoker', 'region']):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    sns.countplot(data=df, x=col)\n",
    "    plt.title(f'Countplot of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"countplots.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be7542",
   "metadata": {},
   "source": [
    "#### 2.2: Missing Data and Clean Data\n",
    "- The dataset was already clean with no missing values.\n",
    "- Categorical variables were identified (`sex`, `smoker`, `region`) and will be converted to numerical values in the next section.\n",
    "- BMI and charges contain outliers, but instead of removing them, I chose to **clip BMI** and **log-transform charges** to preserve useful signal while reducing skew."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1013986",
   "metadata": {},
   "source": [
    "### 2.3 Feature selection and engineering\n",
    "- Create new features (as applicable).\n",
    "- Transform or combine existing features to improve model performance (as applicable).\n",
    "- Scale or normalize data (as applicable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb66a2f3",
   "metadata": {},
   "source": [
    "#### Note: 2.3:\n",
    "- I created two engineered features:\n",
    "  - `bmi_smoker`: Highlights compounded risk from high BMI and smoking.\n",
    "  - `age_group`: Clusters individuals into life stages for better interpretability.\n",
    "- I clipped BMI to reduce outlier distortion and log-transformed `charges` to normalize the target distribution.\n",
    "- I scaled all features to prepare for linear regression and other models sensitive to magnitude differences.\n",
    "- A Decision Tree Regressor was used to visualize feature importance:\n",
    "  - `smoker` and `bmi_smoker` ranked highest—strongly associated with insurance charges.\n",
    "  - This insight guided my final feature selection for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada39cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the custom preparation function\n",
    "def prepare_features(df, transform_target=True, scale=True):\n",
    "    \"\"\"Preprocess and engineer features from the insurance dataset.\"\"\"\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    # Encode categorical variables\n",
    "    label_encoders = {}\n",
    "    for col in ['sex', 'smoker', 'region']:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # Winsorize BMI\n",
    "    bmi_lower = df_encoded['bmi'].quantile(0.05)\n",
    "    bmi_upper = df_encoded['bmi'].quantile(0.95)\n",
    "    df_encoded['bmi'] = df_encoded['bmi'].clip(bmi_lower, bmi_upper)\n",
    "\n",
    "    # Log-transform charges\n",
    "    if transform_target:\n",
    "        df_encoded['charges'] = np.log1p(df_encoded['charges'])\n",
    "\n",
    "    # Feature engineering\n",
    "    df_encoded['bmi_smoker'] = df_encoded['bmi'] * df_encoded['smoker']\n",
    "    df_encoded['age_group'] = pd.cut(df_encoded['age'], bins=[17, 30, 45, 60, 100], labels=[0, 1, 2, 3]).astype(int)\n",
    "\n",
    "    # Feature and target selection\n",
    "    feature_cols = ['age', 'bmi', 'children', 'sex', 'smoker', 'region', 'bmi_smoker', 'age_group']\n",
    "    X = df_encoded[feature_cols]\n",
    "    y = df_encoded['charges']\n",
    "\n",
    "    # Scale features\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    return X, y, df_encoded\n",
    "\n",
    "# Call the function\n",
    "X, y, df_ready = prepare_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance using Decision Tree\n",
    "\n",
    "# Train the model\n",
    "tree = DecisionTreeRegressor(random_state=42)\n",
    "tree.fit(X, y)\n",
    "\n",
    "# Extract and plot importances\n",
    "importances = pd.Series(tree.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=importances.values, y=importances.index)\n",
    "plt.title('Feature Importance (Decision Tree)')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"feature_importance.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb0bff9",
   "metadata": {},
   "source": [
    "#### Reflection 2: \n",
    "- _What patterns or anomalies do you see?_\n",
    "The charges column was heavily skewed, with a small number of folks racking up some seriously high costs. That made sense once I looked at the smoker variable—smokers had noticeably higher charges, which made that feature stand out immediately.\n",
    "\n",
    "- Do any features stand out? What preprocessing steps were necessary to clean and improve the data? \n",
    "I also noticed that BMI had a long tail—some really high values that could mess with the model. \n",
    "\n",
    "- Did you create or modify any features to improve performance?\n",
    "So instead of dropping those rows, I clipped BMI to a reasonable range (just the 5th to 95th percentile) to keep things balanced without losing too much signal. I used AI assistance to findd oput what to do with the BMI and charges.  Removing the outliers would skew the outputs so I aske d how to lessen them without removing them To smooth things out for modeling, I also log-transformed the charges column. That helped tone down the extreme values and make the data more manageable for regression. Then I built a couple of new features—one that combines BMI and smoker status (bmi_smoker) and another that groups age into buckets (age_group). Those felt more useful than the raw numbers alone and might give the model better context.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ffa35",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b15c34",
   "metadata": {},
   "source": [
    "### 3.1 Choose features and target\n",
    "  - Select two or more input features (numerical for regression, numerical and/or categorical for classification)\n",
    "  - Select a target variable (as applicable)\n",
    "  - Regression: Continuous target variable (e.g., price, temperature).\n",
    "  - Classification: Categorical target variable (e.g., gender, species).\n",
    "  - Clustering: No target variable.\n",
    "  - Justify your selection with reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the data for faster pairplot rendering\n",
    "sample_df = df_ready.sample(n=200, random_state=42)\n",
    "\n",
    "# Pairplot for selected features\n",
    "sns.pairplot(sample_df[['age', 'bmi', 'children', 'charges', 'bmi_smoker']])\n",
    "plt.suptitle(\"Pairplot of Key Features vs Charges\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"pairplot_features.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "corr = df_ready[['age', 'bmi', 'children', 'charges', 'smoker', 'bmi_smoker', 'age_group']].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"heatmap_correlation.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de8f4a7",
   "metadata": {},
   "source": [
    "### 3.2 Define X and y\n",
    "  - Assign input features to X\n",
    "  - Assign target variable to y (as applicable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target selection already handled by the prepare_features function\n",
    "X, y, df_ready = prepare_features(df)\n",
    "\n",
    "# Sanity check\n",
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba111909",
   "metadata": {},
   "source": [
    "#### Reflection 3: \n",
    "  - Why did you choose these features?_\\\n",
    "To support my feature selection, I used a pairplot and a correlation heatmap. The pairplot helped visualize how features like `bmi`, `age`, and the engineered `bmi_smoker` relate to the target variable `charges`. The heatmap confirmed that `smoker`, `bmi_smoker`, and `age` have the strongest correlations with charges. This guided my decision to keep those features in the model, along with `sex`, `region`, and `age_group` to capture additional context and variation.\n",
    "\n",
    "  - How might they impact predictions or accuracy?\n",
    "These features were chosen because of their correlation but also because they represent real-world factors that influence medical costs. Including them helps the model detect both general trends and high-risk subgroups. By engineering features like bmi_smoker and grouping age, I hope to improve the model’s accuracy without overfitting. These choices made the model more balanced—able to predict for common cases while still accounting for the influence of higher-risk individuals.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c5ec0",
   "metadata": {},
   "source": [
    "## Section 4. Train a Model (Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746eb30",
   "metadata": {},
   "source": [
    "### 4.1 Split the data into training and test sets using train_test_split (or StratifiedShuffleSplit if class imbalance is an issue).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "sns.histplot(y_train, kde=True, label=\"Train\", color=\"skyblue\")\n",
    "sns.histplot(y_test, kde=True, label=\"Test\", color=\"salmon\")\n",
    "plt.title(\"Distribution of Charges (Train vs Test)\")\n",
    "plt.xlabel(\"Log(Charges)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"charges_distribution_split.png\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bbaba3",
   "metadata": {},
   "source": [
    "### 4.2 Train model using Scikit-Learn model.fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature names and coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_\n",
    "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(coef_df)\n",
    "# Plot the coefficients\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=coef_df)\n",
    "plt.title(\"Linear Model Coefficients\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"linear_model_coefficients.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dbe119",
   "metadata": {},
   "source": [
    "### 4.3 Evalulate performance, for example:\n",
    "  - Regression: R^2, MAE, RMSE (RMSE has been recently updated)\n",
    "  - Classification: Accuracy, Precision, Recall, F1-score, Confusion Matrix\n",
    "  - Clustering: Inertia, Silhouette Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cde62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Create a DataFrame to store model evaluation metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Model\": [\"Manual Linear Regression\"],\n",
    "    \"R²\": [r2],\n",
    "    \"MAE\": [mae],\n",
    "    \"RMSE\": [rmse]\n",
    "})\n",
    "\n",
    "# Save (optional at this stage)\n",
    "csv_path = os.path.join(output_dir, \"model_metrics.csv\")\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--') \n",
    "plt.title(\"Actual vs Predicted Charges\")\n",
    "plt.xlabel(\"Actual Charges (Log Scale)\")\n",
    "plt.ylabel(\"Predicted Charges (Log Scale)\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"actual_vs_predicted.png\"))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "print(f\"Explained Variance Score: {evs:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6568fff7",
   "metadata": {},
   "source": [
    "#### Reflection 4: \n",
    "  -  _How well did the model perform?_\n",
    "Overall, the model did a solid job. With an R² around 0.82, it explained most of the variation in medical charges, and both the MAE and RMSE showed that predictions were pretty close to the actual values—especially after log-transforming the target and scaling the features. \n",
    "\n",
    "  - Any surprises in the results?_\n",
    "One of the more satisfying surprises was how much value the bmi_smoker feature added. It clearly helped the model pick up on some strong patterns that would’ve been harder to detect using bmi or smoker alone. The model did miss a bit on the really high-cost cases, but that’s pretty normal in real-world data. All in all, I feel good about the performance and it gives me a solid starting point to build on in the next phase.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33150a1",
   "metadata": {},
   "source": [
    "## Section 5. Improve the Model or Try Alternates (Implement Pipelines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9b3da",
   "metadata": {},
   "source": [
    "### 5.1 Implement Pipeline 1: Imputer → StandardScaler → Linear Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c660dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Pipeline 1: Imputer → StandardScaler → Linear Regression\n",
    "pipeline1 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit pipeline to training data\n",
    "pipeline1.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_pipe1 = pipeline1.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "r2_pipe1 = r2_score(y_test, y_pred_pipe1)\n",
    "mae_pipe1 = mean_absolute_error(y_test, y_pred_pipe1)\n",
    "rmse_pipe1 = np.sqrt(mean_squared_error(y_test, y_pred_pipe1))\n",
    "\n",
    "# Append to existing metrics_df\n",
    "metrics_df = pd.concat([\n",
    "    metrics_df,\n",
    "    pd.DataFrame({\n",
    "        \"Model\": [\"Linear Regression (Pipeline 1)\"],\n",
    "        \"R²\": [r2_pipe1],\n",
    "        \"MAE\": [mae_pipe1],\n",
    "        \"RMSE\": [rmse_pipe1]\n",
    "    })\n",
    "], ignore_index=True)\n",
    "\n",
    "# Optional: Save updated DataFrame\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Output results\n",
    "print(f\"Pipeline 1 - R² Score: {r2_pipe1:.4f}\")\n",
    "print(f\"Pipeline 1 - Mean Absolute Error (MAE): {mae_pipe1:.4f}\") \n",
    "print(f\"Pipeline 1 - Root Mean Squared Error (RMSE): {rmse_pipe1:.4f}\")\n",
    "\n",
    "# Plot actual vs predicted values for Pipeline 1\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_test, y_pred_pipe1, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--') \n",
    "plt.title(\"Pipeline 1: Actual vs Predicted Charges\")\n",
    "plt.xlabel(\"Actual Charges (Log Scale)\")    \n",
    "plt.ylabel(\"Predicted Charges (Log Scale)\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"pipeline1_actual_vs_predicted.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3221209",
   "metadata": {},
   "source": [
    "### 5.2 Implement Pipeline 2: Imputer → Polynomial Features (degree=3) → StandardScaler → Linear Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e31dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Pipeline 2: Imputer → PolynomialFeatures → StandardScaler → LinearRegression\n",
    "pipeline2 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('poly', PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit pipeline to training data\n",
    "pipeline2.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_pipe2 = pipeline2.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "r2_pipe2 = r2_score(y_test, y_pred_pipe2)\n",
    "mae_pipe2 = mean_absolute_error(y_test, y_pred_pipe2)\n",
    "rmse_pipe2 = np.sqrt(mean_squared_error(y_test, y_pred_pipe2))\n",
    "\n",
    "# Output results\n",
    "print(f\"Pipeline 2 - R² Score: {r2_pipe2:.4f}\") \n",
    "print(f\"Pipeline 2 - Mean Absolute Error (MAE): {mae_pipe2:.4f}\")\n",
    "print(f\"Pipeline 2 - Root Mean Squared Error (RMSE): {rmse_pipe2:.4f}\")\n",
    "\n",
    "# Append to existing metrics_df\n",
    "metrics_df = pd.concat([\n",
    "    metrics_df,\n",
    "    pd.DataFrame({\n",
    "        \"Model\": [\"Polynomial Regression (Pipeline 2)\"],\n",
    "        \"R²\": [r2_pipe2],\n",
    "        \"MAE\": [mae_pipe2],\n",
    "        \"RMSE\": [rmse_pipe2]\n",
    "    })\n",
    "], ignore_index=True)\n",
    "\n",
    "# Final save of full metrics\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Plot actual vs predicted values for Pipeline 2\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_test, y_pred_pipe2, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.title(\"Pipeline 2: Actual vs Predicted Charges\")\n",
    "plt.xlabel(\"Actual Charges (Log Scale)\")\n",
    "plt.ylabel(\"Predicted Charges (Log Scale)\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"pipeline2_actual_vs_predicted.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d838e5e5",
   "metadata": {},
   "source": [
    "### 5.3 Compare performance of all models across the same performance metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure 'metrics_df' is indexed by Model\n",
    "metrics_df_plot = metrics_df.copy()\n",
    "metrics_df_plot.index = metrics_df_plot[\"Model\"] if \"Model\" in metrics_df_plot.columns else metrics_df_plot.index\n",
    "\n",
    "# Extract values\n",
    "models = metrics_df_plot.index.tolist()\n",
    "metrics = [\"R²\", \"MAE\", \"RMSE\"]\n",
    "\n",
    "# Create bar positions\n",
    "x = np.arange(len(metrics))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot each model's bars\n",
    "for i, model in enumerate(models):\n",
    "    ax.bar(x + i * width, metrics_df_plot.loc[model, metrics], width, label=model)\n",
    "\n",
    "# Add labels and formatting\n",
    "ax.set_ylabel(\"Score / Error\")\n",
    "ax.set_title(\"Model Performance Comparison (Overlayed Metrics)\")\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"overlayed_model_performance.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa368c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare traces for each model\n",
    "fig = go.Figure()\n",
    "\n",
    "for model in metrics_df.index:\n",
    "    fig.add_trace(go.Bar(\n",
    "        name=model,\n",
    "        x=[\"R²\", \"MAE\", \"RMSE\"],\n",
    "        y=[\n",
    "            metrics_df.loc[model, \"R²\"],\n",
    "            metrics_df.loc[model, \"MAE\"],\n",
    "            metrics_df.loc[model, \"RMSE\"]\n",
    "        ]\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Model Performance Comparison (Overlayed)\",\n",
    "    xaxis_title=\"Metrics\",\n",
    "    yaxis_title=\"Score / Error\",\n",
    "    barmode='group',\n",
    "    template='plotly_white',\n",
    "    width=800,\n",
    "    height=500\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Export interactive Plotly figure as standalone HTML\n",
    "fig.write_html(\"docs/model_performance_plot.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c47b21",
   "metadata": {},
   "source": [
    "#### Reflection 5: \n",
    "- _Which models performed better?_\n",
    "Of the three models tested, the Polynomial Regression (Pipeline 2) clearly outperformed the others across all metrics — achieving the highest R² score and the lowest MAE and RMSE. That suggests it did the best job capturing nonlinear relationships in the data. Pipeline 1 (Linear Regression with preprocessing) also improved upon the Manual Linear Regression baseline, showing that even without feature engineering, proper preprocessing steps like imputation and scaling can enhance model performance.\n",
    "\n",
    "- _How does scaling impact results?_\n",
    "Scaling had a noticeable impact, especially in Pipeline 1. By standardizing the features, the model avoided being biased toward variables with larger numeric ranges. This helped improve both the accuracy and consistency of predictions. When combined with polynomial features in Pipeline 2, scaling ensured that the transformed feature space was balanced and the model could converge more efficiently. Bottom line: scaling doesn't just clean up your inputs — it sets the stage for better learning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66bcd43",
   "metadata": {},
   "source": [
    "## Section 6. Final Thoughts & Insights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae8994",
   "metadata": {},
   "source": [
    "### 6.1 Summarize findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf6735c",
   "metadata": {},
   "source": [
    "This project started with a simple goal: predict medical charges based on personal and lifestyle data. What I found along the way is that even basic models can do a decent job, but the real magic happens when you give the data some love. Cleaning things up, scaling features, and engineering a few new ones (like combining BMI and smoker status) made a noticeable difference. The more I refined the model—especially with polynomial features—the better it got at spotting complex patterns. In the end, Pipeline 2 took the lead across all metrics, showing the value of letting the model work with richer feature interactions. Also, no surprise here: being a smoker with a high BMI was a major cost driver. The data backed that up loud and clear. Overall, each modeling step added something meaningful, and it was cool to see theory and practice align so clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059dd3ed",
   "metadata": {},
   "source": [
    "### 6.2 Discuss challenges faced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff9f75c",
   "metadata": {},
   "source": [
    "### Handling Skewed and Outlier-Heavy Data:\n",
    "One of the biggest data-related challenges was dealing with the skewed charges column and extreme BMI values. Instead of dropping outliers,  I took a smarter route by clipping BMI and log-transforming the target, which shows thoughtfulness about preserving signal while improving model fit. What I din't do was realize that the pipeline process would do what I had ask the AI assisitant about earlier. I actually created more work, but learned a new Python capability.\n",
    "\n",
    "### Feature Engineering Without Overfitting:\n",
    "I  wanted to keep the code simple, yet push the boundaries to more advanced thinking. By creating features like bmi_smoker and age_group added depth, but there’s always a challenge in making sure these features improve performance without overcomplicating the model. I used the \"feature Importance\" approach I had found in the midterm to check my work.\n",
    "\n",
    "### Model Comparison and Metric Interpretation:\n",
    "Balancing R², MAE, and RMSE—and understanding what each really tells me—was part of the learning curve. As with all of my projects I didn’t just report metrics; I wanted to SEE and reflect on what they meant, especially when performance improved but high-cost cases were still tough to nail.\n",
    "\n",
    "### Building and Using Pipelines:\n",
    "I had approached the pipelines like seperate projects, and found that I was doing thing over and over again.  I found that pipelines in Scikit-Learn can be tricky when you're stacking multiple steps like imputation, scaling, and polynomial expansion. After a few attmepts I executed it well—but getting those steps right in sequence is a challenge for beginners.\n",
    "\n",
    "### The GitHub Pages “Side Quest”:\n",
    "Hosting an interactive Plotly chart was a challenge outside the modeling world. I wanted to take a minute to configure GitHub Pages, creating the right folder structure, and troubleshooting deployment takes time—,y time gamble was a technical learning moment that I hope pays off later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff54bd3",
   "metadata": {},
   "source": [
    "### 6.3 If you had more time, what would you try next?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0be8d2",
   "metadata": {},
   "source": [
    "If I had more time, I’d run this dataset through a few classification exercises just to see what insights show up when reframing the problem—like predicting whether a patient’s charges exceed a certain threshold. It would be interesting to apply different classification models like Logistic Regression, Decision Trees, or even ensemble methods to compare outcomes. I also tend to take more time than I plan because I like to experiment—I’ll loop back and try different preprocessing steps or tweak model parameters just to see what changes. For me, the learning comes not just from what works, but also from understanding why something works (or doesn’t). That exploratory mindset always opens up new possibilities and teaches me more than I expected going in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9057ec",
   "metadata": {},
   "source": [
    "#### Reflection 6:\n",
    "- What did you learn from this project?\n",
    "This project helped me connect the dots between theory and practice. I didn’t just learn how to build a regression model—I learned how each step in the process can either help or hurt the final result. Things like scaling, log-transforming the target, and engineering features like bmi_smoker made a noticeable difference. The extra exploration—like building pipelines, testing polynomial features, and comparing multiple models—taught me how small adjustments can lead to meaningful improvements. And setting up GitHub Pages to share an interactive chart? That was new territory for me. It wasn’t always smooth, but figuring it out made the work feel more real and shareable. What stuck with me most, though, is how much value there is in going back and playing with the pieces—trying new things, seeing what happens, and learning through the process. I always take more time than I expect, but it’s worth it for the insight I get along the way.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
